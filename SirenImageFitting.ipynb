{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomdct/BlogColabScripts/blob/main/SirenImageFitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image fitting with a SIREN**\n",
        "\n",
        "---\n",
        "\n",
        "We investigate fitting an image with a SIREN. The original SIREN project page is available [here](https://www.vincentsitzmann.com/siren/), and our code has been partially adapted from theirs.\n",
        "\n",
        "(**N.B.** You should run the code on this page with the GPU enabled, which you can find under `Runtime > Change runtime type > Hardware accelerator`.)\n"
      ],
      "metadata": {
        "id": "KCgxqG7_BA9s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C3mgyAiMQ7v"
      },
      "source": [
        "## **Preliminary business**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "k2uEjwUKmHby"
      },
      "outputs": [],
      "source": [
        "#@title We start by making all of the imports that we will need.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import Resize, Compose, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ihH8qNSsmMco"
      },
      "outputs": [],
      "source": [
        "#@title Next we load our image.\n",
        "\n",
        "# Loading the image from a url.\n",
        "\n",
        "img_url = 'https://cdn.britannica.com/79/150179-050-E2707D87/human-eye.jpg'\n",
        "response = requests.get(img_url)\n",
        "eye_img = Image.open(BytesIO(response.content))\n",
        "\n",
        "# We reduce everything down by a scale factor of four, to\n",
        "# speed up the experiments. To use the original image set\n",
        "# scale_factor = 1\n",
        "\n",
        "scale_factor = 4\n",
        "eye_img = eye_img.resize([eye_img.width // scale_factor, eye_img.height // scale_factor])\n",
        "\n",
        "# Collect height, width and number of channels (in this case 3, for RGB)\n",
        "\n",
        "img_width = eye_img.size[0]\n",
        "img_height = eye_img.size[1]\n",
        "img_size = (img_height, img_width)\n",
        "no_of_channels = len(eye_img.getbands())\n",
        "\n",
        "# Now show the eye image.\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "\n",
        "ax.imshow(eye_img)\n",
        "ax.set_title('This is the eye image we will be using:')\n",
        "ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "cellView": "form",
        "id": "v7FCjs8V3CGO"
      },
      "outputs": [],
      "source": [
        "#@title Converting an image into a tensor and creating a grid\n",
        "\n",
        "# Converting an image to a tensor converst RGB values to\n",
        "# floats with values in [0, 1]. We rescale to get values\n",
        "# in [-1, 1].\n",
        "\n",
        "def image_to_tensor(img):\n",
        "    transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize(torch.Tensor([0.5]),torch.Tensor([0.5]))\n",
        "    ])\n",
        "    return transform(img)\n",
        "\n",
        "# Creates an array of grid coordinates\n",
        "\n",
        "def create_grid(grid_steps, bounds=None):\n",
        "    # given the input\n",
        "    #    grid_steps = (a_1,a_2,...,a_n)\n",
        "    # creates an array of coordinates in an n-dimensional grid with a_i steps\n",
        "    # in the ith dimension. If bounds=None then the bounds are [-1,1]\n",
        "\n",
        "    grid_dim = len(grid_steps)\n",
        "\n",
        "    if bounds == None:\n",
        "        bounds = [ [-1,1] for i in range(grid_dim)]\n",
        "\n",
        "    tensors = tuple( [ torch.linspace(bounds[i][0],\n",
        "                                      bounds[i][1],\n",
        "                                      steps=grid_steps[i]\n",
        "                                      ) for i in range(grid_dim) ] )\n",
        "\n",
        "    my_grid = torch.stack(torch.meshgrid(*tensors), dim=-1)\n",
        "    return my_grid.reshape(-1, grid_dim)\n",
        "\n",
        "# Define a dataloader for obtaining the RGB values at each pixel.\n",
        "\n",
        "class ImageFitter(Dataset):\n",
        "    def __init__(self, img):\n",
        "        super().__init__()\n",
        "        img_tensor = image_to_tensor(img)\n",
        "        self.pixels = img_tensor.permute(1, 2, 0).view(-1, no_of_channels)\n",
        "        self.coords = create_grid((img.height, img.width))\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx > 0: raise IndexError\n",
        "\n",
        "        return self.coords, self.pixels\n",
        "\n",
        "img_fitter = ImageFitter(eye_img)\n",
        "dataloader = DataLoader(img_fitter, batch_size=1, pin_memory=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "cTmR0W1wajG4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Define SineLayer and Siren\n",
        "\n",
        "class SineLayer(nn.Module):\n",
        "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
        "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the nonlinearity. Different signals may require different omega_0 in the first layer - this is a hyperparameter.\n",
        "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
        "\n",
        "    def __init__(self, in_features, out_features, bias=True, is_first=False, omega_0=30):\n",
        "        super().__init__()\n",
        "        self.omega_0 = omega_0\n",
        "        self.is_first = is_first\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.in_features,\n",
        "                                             1 / self.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0,\n",
        "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.sin(self.omega_0 * self.linear(input))\n",
        "\n",
        "\n",
        "class Siren(nn.Module):\n",
        "    def __init__(self, *layer_sizes, outermost_linear=False, first_omega_0=30, hidden_omega_0=30.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.no_of_layers = len(layer_sizes)\n",
        "        self.net = []\n",
        "\n",
        "        # First layer\n",
        "        self.net.append(SineLayer(layer_sizes[0], layer_sizes[1], is_first=True, omega_0=first_omega_0))\n",
        "\n",
        "        # Hidden layers\n",
        "        for i in range(1, self.no_of_layers - 2):\n",
        "            self.net.append(SineLayer(layer_sizes[i], layer_sizes[i+1],\n",
        "                                          is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        # Last layer\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Linear( layer_sizes[self.no_of_layers-2], layer_sizes[self.no_of_layers-1] )\n",
        "\n",
        "            with torch.no_grad():\n",
        "                final_linear.weight.uniform_(-np.sqrt(6 / layer_sizes[self.no_of_layers-1]) / hidden_omega_0,\n",
        "                                              np.sqrt(6 / layer_sizes[self.no_of_layers-1]) / hidden_omega_0)\n",
        "\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SineLayer(layer_sizes[self.no_of_layers-2], layer_sizes[self.no_of_layers-1],\n",
        "                                      is_first=False, omega_0=hidden_omega_0))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
        "        output = self.net(coords)\n",
        "        return output, coords\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "aHcRc2LA1kz6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "FZJH_qfki67e",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Implement the training loop\n",
        "\n",
        "# Define the siren and optimiser\n",
        "\n",
        "img_siren = Siren(2, 256, 256, 256, 3, outermost_linear=True, first_omega_0=30, hidden_omega_0=30)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    img_siren.cuda()\n",
        "\n",
        "optim = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
        "\n",
        "# Implement the summary step.\n",
        "\n",
        "def print_summary(step, loss, model_output):\n",
        "    fig, ax = plt.subplots(1,2)\n",
        "    model_output = (model_output + 1)/2\n",
        "    a = model_output.cpu().permute(1,2,0).view(img_height, img_width, no_of_channels).detach().numpy()\n",
        "    ax[0].imshow(a)\n",
        "    ax[0].set_title(f\"After %d steps, loss=%0.6f.\" % (step, loss))\n",
        "    ax[1].imshow(eye_img)\n",
        "    ax[1].set_title(f\"Original image\")\n",
        "    plt.show()\n",
        "\n",
        "# Define the training loop.\n",
        "\n",
        "def run_through_training_loop(total_steps, steps_til_summary):\n",
        "\n",
        "    model_input, ground_truth = next(iter(dataloader))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
        "\n",
        "    for step in range(total_steps+1):\n",
        "        model_output, coords = img_siren(model_input)\n",
        "        loss = ((model_output - ground_truth)**2).mean()\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        if not step % steps_til_summary:\n",
        "            print_summary(step, loss, model_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A94-O7FmA6bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 1: train a SIREN to fit the image.**\n",
        "\n",
        "We..."
      ],
      "metadata": {
        "id": "YACKaJnAAW_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kME9wAuVJp0z"
      },
      "outputs": [],
      "source": [
        "run_through_training_loop(5000, 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 2: check for any improvement in resolution.**\n",
        "\n",
        "We..."
      ],
      "metadata": {
        "id": "r1BxFnEZAb2s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNpMHv_kk9dT"
      },
      "outputs": [],
      "source": [
        "#@title Check the improvement in resolution of the close-up patches.\n",
        "\n",
        "# We pick out three close-up patches which we will use to\n",
        "# test the resolution capabilities of our siren.\n",
        "\n",
        "top_left_pixels = [[230, 338], [336, 174], [630, 200]]\n",
        "\n",
        "fig,ax = plt.subplots(1,3, figsize=(8,8*3))\n",
        "ax[1].set_title('Here are three close-ups:')\n",
        "\n",
        "for i in range(3):\n",
        "    a, b = top_left_pixels[i][0] // scale_factor, top_left_pixels[i][1] // scale_factor\n",
        "    patch_size = 128 // scale_factor\n",
        "    ax[i].imshow(eye_img.crop((a,b,a+patch_size,b+patch_size)))\n",
        "    ax[i].axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    fig,ax = plt.subplots(3,2, figsize=(8,12))\n",
        "\n",
        "    for i in range(3):\n",
        "        a, b = top_left_pixels[i][0], top_left_pixels[i][1]\n",
        "        zoomed_in_region = create_grid((512,512), bounds = [[2*b/img_height - 1, 2*(b + patch_width)/img_height - 1],\n",
        "                                                            [2*a/img_width - 1,2*(a + patch_width)/img_width - 1]])\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            zoomed_in_region = zoomed_in_region.cuda()\n",
        "\n",
        "        model_out, _ = img_siren(zoomed_in_region)\n",
        "        model_out = (model_out + 1)/2\n",
        "        ax[i,0].axis('off')\n",
        "        ax[i,1].axis('off')\n",
        "        ax[i,0].imshow(model_out.cpu().view(512,512,3).detach().numpy())\n",
        "        ax[i,1].imshow(eye_img.crop((a,b,a + patch_width,b + patch_width)))\n",
        "    ax[0,0].set_title(f\"SIREN\")\n",
        "    ax[0,1].set_title(f\"Original image\")\n",
        "\n",
        "    fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 3: comparision with other types of activation functions.**\n",
        "\n",
        "We now implement simple ReLU and sigmoid networks with identical layers, and see the difference in how quickly the corresponding network can learn the image."
      ],
      "metadata": {
        "id": "GctotFcC5B-A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LNDRn1PTH6E3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Define simple ReLU and Sigmoid networks\n",
        "\n",
        "# ReLU layers and ReLU networks\n",
        "\n",
        "class ReLULayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.relu(self.linear(input))\n",
        "\n",
        "class ReLUNetwork(nn.Module):\n",
        "    def __init__(self, *layer_sizes, outermost_linear=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.no_of_layers = len(layer_sizes)\n",
        "        self.net = []\n",
        "\n",
        "        # First and hidden layers\n",
        "        for i in range(0, self.no_of_layers - 2):\n",
        "            self.net.append(ReLULayer(layer_sizes[i], layer_sizes[i+1]))\n",
        "\n",
        "        # Last layer\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Linear( layer_sizes[self.no_of_layers-2], layer_sizes[self.no_of_layers-1] )\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(ReLULayer(layer_sizes[self.no_of_layers-2], layer_sizes[self.no_of_layers-1]))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
        "        output = self.net(coords)\n",
        "        return output, coords\n",
        "\n",
        "# sigmoid layers and sigmoid networks\n",
        "\n",
        "class SigmoidLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super().__init__()\n",
        "        self.in_features = in_features\n",
        "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return torch.sigmoid(self.linear(input))\n",
        "\n",
        "class SigmoidNetwork(nn.Module):\n",
        "    def __init__(self, *layer_sizes, outermost_linear=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.no_of_layers = len(layer_sizes)\n",
        "        self.net = []\n",
        "\n",
        "        # First and hidden layers\n",
        "        for i in range(0, self.no_of_layers - 2):\n",
        "            self.net.append(SigmoidLayer(layer_sizes[i], layer_sizes[i+1]))\n",
        "\n",
        "        # Last layer\n",
        "        if outermost_linear:\n",
        "            final_linear = nn.Linear( layer_sizes[self.no_of_layers-2], layer_sizes[self.no_of_layers-1] )\n",
        "            self.net.append(final_linear)\n",
        "        else:\n",
        "            self.net.append(SigmoidLayer(layer_sizes[self.no_of_layers-2], layer_sizes[self.no_of_layers-1]))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, coords):\n",
        "        coords = coords.clone().detach().requires_grad_(True) # allows to take derivative w.r.t. input\n",
        "        output = self.net(coords)\n",
        "        return output, coords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-kVaRtsk7P5v"
      },
      "outputs": [],
      "source": [
        "#@title A comparison of different models\n",
        "\n",
        "\n",
        "# Define the three different models and their optimisers\n",
        "\n",
        "img_siren   = Siren(2, 256, 256, 256, 3, outermost_linear=True, first_omega_0=30, hidden_omega_0=30)\n",
        "img_relu    = ReLUNetwork(2, 256, 256, 256, 3, outermost_linear=True)\n",
        "img_sigmoid = SigmoidNetwork(2, 256, 256, 256, 3, outermost_linear=True)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    img_siren.cuda()\n",
        "    img_relu.cuda()\n",
        "    img_sigmoid.cuda()\n",
        "\n",
        "optim_siren   = torch.optim.Adam(lr=1e-4, params=img_siren.parameters())\n",
        "optim_relu    = torch.optim.Adam(lr=1e-4, params=img_relu.parameters())\n",
        "optim_sigmoid = torch.optim.Adam(lr=1e-4, params=img_sigmoid.parameters())\n",
        "\n",
        "# Comparison summary for the training loop.\n",
        "\n",
        "def print_comparison_summary(step, model_output):\n",
        "    fig, ax = plt.subplots(1,4)\n",
        "    titles = [\"Sin\",\"ReLU\",\"Sigmoid\"]\n",
        "    for i in range(3):\n",
        "        ax[i].axis('off')\n",
        "        model_output[i] = (model_output[i] + 1)/2\n",
        "        a = model_output[i].cpu().permute(1,2,0).view(img_height, img_width, no_of_channels).detach().numpy()\n",
        "        ax[i].imshow(a)\n",
        "        ax[i].set_title(titles[i])\n",
        "    ax[3].axis('off')\n",
        "    ax[3].imshow(eye_img)\n",
        "    ax[3].set_title(f\"Original image\")\n",
        "    plt.show()\n",
        "\n",
        "# Implement the training loop.\n",
        "\n",
        "def comparison_training_loop(total_steps, steps_til_summary):\n",
        "\n",
        "    model_input, ground_truth = next(iter(dataloader))\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model_input, ground_truth = model_input.cuda(), ground_truth.cuda()\n",
        "\n",
        "    for step in range(total_steps+1):\n",
        "        model_outputs = []\n",
        "        losses = []\n",
        "\n",
        "        for model_and_optim in [ [ img_siren,   optim_siren   ],\n",
        "                                 [ img_relu,    optim_relu    ],\n",
        "                                 [ img_sigmoid, optim_sigmoid ]]:\n",
        "\n",
        "            model = model_and_optim[0]\n",
        "            optim = model_and_optim[1]\n",
        "\n",
        "            model_output, coords = model(model_input)\n",
        "            model_outputs.append(model_output)\n",
        "\n",
        "            loss = ((model_output - ground_truth)**2).mean()\n",
        "            losses.append(loss)\n",
        "\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "        if not step % steps_til_summary:\n",
        "            print(f\"Siren, ReLU and Sigmoid after %d steps, with losses %0.6f, %0.6f, %0.6f.\" % (step, losses[0], losses[1], losses[2]))\n",
        "            print_comparison_summary(step, model_outputs)\n",
        "\n",
        "\n",
        "\n",
        "comparison_training_loop(5000,100)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 4: messing around with the SIREN.**"
      ],
      "metadata": {
        "id": "wwtF5lVWCEj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we..."
      ],
      "metadata": {
        "id": "j_aesnX9CNbd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4C3mgyAiMQ7v",
        "YACKaJnAAW_g",
        "r1BxFnEZAb2s",
        "GctotFcC5B-A",
        "wwtF5lVWCEj-"
      ],
      "authorship_tag": "ABX9TyOh5WqZafk/4KIpwOEeY6jX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}